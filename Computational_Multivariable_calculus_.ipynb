{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate Calculus\n",
        "\n",
        "This notebook contains code for techniques is multivariable calculus using automatic differentiation frameworks and scipy for crucial calculus topics that form the basis of all other calculus topics.\n"
      ],
      "metadata": {
        "id": "zdVZjaFONq9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Day 1: Partial Derivatives through Engineering Necessity\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Compute partial derivatives $∂f/∂x$, $∂f/∂y$ for multivariable functions.\n",
        "- Interpret partial derivatives as physical rates of change.\n",
        "- Implement derivatives in PyTorch, JAX, SciPy with 3D visualizations.\n",
        "- Connect to thermal management in metamaterial design.\n",
        "---\n",
        "\n",
        "## Real-World Problem: Chip Cooling\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "An electronic chip has temperature distribution `$T(x, y) = 100 * exp(-0.1 * x^2 - 0.2 * y^2) + 50 * sin(0.5 * x) * cos(0.3 * y)$`, where x, y are coordinates (cm). Engineers need to:\n",
        "\n",
        "1. Identify hotspots where temperature changes rapidly.\n",
        "2. Calculate cooling rates in x- and y-directions.\n",
        "3. Ensure temperature $<150°C$."
      ],
      "metadata": {
        "id": "hiFc4uVIxxn-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f42ShyYCf59",
        "outputId": "a2cadc04-91ea-4822-9b14-a9bc2c49edd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-7.0205865 , -4.543504  , -2.0637805 ,  0.3654875 ,  2.6926434 ,\n",
              "         4.868886  ,  6.849438  ,  8.594774  , 10.071558  , 11.253549  ,\n",
              "        12.12223   , 12.667285  , 12.886848  , 12.787534  , 12.3842325 ,\n",
              "        11.699725  , 10.76406   ,  9.613774  ,  8.290935  ,  6.842077  ,\n",
              "         5.317027  ,  3.767726  ,  2.247037  ,  0.8076581 , -0.4988203 ,\n",
              "        -1.6226593 , -2.516456  , -3.1353793 , -3.437185  , -3.3821945 ,\n",
              "        -2.933407  , -2.0571527 , -0.72462654,  1.0852727 ,  3.381544  ,\n",
              "         6.1551213 ,  9.371784  , 12.964878  , 16.829277  , 20.818485  ,\n",
              "        24.746645  , 28.39701   , 31.537346  , 33.94153   , 35.41503   ,\n",
              "        35.820637  , 35.1       , 33.286674  , 30.507465  , 26.97069   ,\n",
              "        22.942625  , 18.715607  , 14.572897  , 10.756366  ,  7.442032  ,\n",
              "         4.7270947 ,  2.6295767 ,  1.0994139 ,  0.03773117, -0.67991257,\n",
              "        -1.1806889 , -1.5756121 , -1.9468856 , -2.3421187 , -2.7748504 ,\n",
              "        -3.2298536 , -3.671257  , -4.0516405 , -4.3205647 , -4.4315987 ,\n",
              "        -4.34734   , -4.0424547 , -3.5049772 , -2.7362502 , -1.7499751 ,\n",
              "        -0.57066405,  0.76815856,  2.2258759 ,  3.756678  ,  5.311405  ,\n",
              "         6.839289  ,  8.289586  ,  9.613139  , 10.763768  , 11.699594  ,\n",
              "        12.384175  , 12.787509  , 12.886839  , 12.667281  , 12.122228  ,\n",
              "        11.253549  , 10.071558  ,  8.594774  ,  6.849438  ,  4.868886  ,\n",
              "         2.6926434 ,  0.3654875 , -2.0637805 , -4.543504  , -7.0205865 ],\n",
              "       dtype=float32),\n",
              " array([  2.029851  ,   2.9600625 ,   3.8825843 ,   4.7664704 ,\n",
              "          5.581668  ,   6.299843  ,   6.895093  ,   7.344663  ,\n",
              "          7.6295304 ,   7.734933  ,   7.650745  ,   7.371769  ,\n",
              "          6.8978744 ,   6.2340174 ,   5.39013   ,   4.380878  ,\n",
              "          3.2253015 ,   1.9463571 ,   0.5703797 ,  -0.87351125,\n",
              "         -2.3540108 ,  -3.8381915 ,  -5.291956  ,  -6.680313  ,\n",
              "         -7.9673896 ,  -9.116091  , -10.087427  , -10.839458  ,\n",
              "        -11.32607   , -11.495844  , -11.291569  , -10.651023  ,\n",
              "         -9.509888  ,  -7.807575  ,  -5.4964504 ,  -2.554512  ,\n",
              "          0.9994297 ,   5.0899086 ,   9.571286  ,  14.220249  ,\n",
              "         18.738066  ,  22.765644  ,  25.91241   ,  27.797611  ,\n",
              "         28.099424  ,  26.604658  ,  23.250277  ,  18.14811   ,\n",
              "         11.586321  ,   4.00512   ,  -4.051007  , -11.997398  ,\n",
              "        -19.27945   , -25.43699   , -30.152552  , -33.27645   ,\n",
              "        -34.826294  , -34.963455  , -33.952915  , -32.115047  ,\n",
              "        -29.7781    , -27.238491  , -24.733618  , -22.428377  ,\n",
              "        -20.414455  , -18.719246  , -17.320635  , -16.163916  ,\n",
              "        -15.177848  , -14.2879505 , -13.426134  , -12.536609  ,\n",
              "        -11.578653  , -10.527016  ,  -9.370722  ,  -8.111077  ,\n",
              "         -6.7593126 ,  -5.334278  ,  -3.8602877 ,  -2.3652537 ,\n",
              "         -0.87908727,   0.5676841 ,   1.9450868 ,   3.2247179 ,\n",
              "          4.3806167 ,   5.3900156 ,   6.2339687 ,   6.8978543 ,\n",
              "          7.3717604 ,   7.650742  ,   7.734932  ,   7.6295304 ,\n",
              "          7.344663  ,   6.895093  ,   6.299843  ,   5.581668  ,\n",
              "          4.7664704 ,   3.8825843 ,   2.9600625 ,   2.029851  ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Define a temperature-like scalar field T(x, y)\n",
        "# Combines an exponential decay term and an oscillatory sine-cosine term\n",
        "def T(x, y):\n",
        "    return 100 * torch.exp(-0.1 * x**2 - 0.2 * y**2) + 50 * torch.sin(0.5 * x) * torch.cos(0.3 * y)\n",
        "\n",
        "def partials():\n",
        "    # Create evenly spaced points for x and y across [-10, 10]\n",
        "    # requires_grad=True lets PyTorch track operations for differentiation\n",
        "    x = torch.linspace(-10, 10, 100, requires_grad=True)\n",
        "    y = torch.linspace(-10, 10, 100, requires_grad=True)\n",
        "\n",
        "    # Evaluate the scalar field\n",
        "    Z = T(x, y)\n",
        "\n",
        "    # Compute ∂T/∂x and ∂T/∂y using autograd\n",
        "    # Since T is a scalar field in two variables, we backpropagate from Z\n",
        "    Z.backward(torch.ones_like(Z))\n",
        "\n",
        "    # Gradient of T w.r.t x\n",
        "    dT_dx = x.grad\n",
        "\n",
        "    # Gradient of T w.r.t y\n",
        "    # (Note: gradients accumulate by default — they should be zeroed out if re-used)\n",
        "    dT_dy = y.grad\n",
        "\n",
        "    # Convert from tensors to NumPy arrays for visualization or further analysis\n",
        "    return dT_dx.detach().numpy(), dT_dy.detach().numpy(), x.detach().numpy(), y.detach().numpy()\n",
        "\n",
        "# Compute both partial derivatives and the coordinate grids\n",
        "dT_dx, dT_dy, x, y = partials()\n",
        "\n",
        "# Display or inspect computed partial derivatives\n",
        "dT_dx, dT_dy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def partials_jax():\n",
        "\n",
        "  # define the scalar field\n",
        "  # combines exponential decay and oscillation just like in pytorch version\n",
        "  def T(x,y):\n",
        "    return 100 * jnp.exp(-0.1 * x**2 - 0.2 * y**2) + 50 * jnp.sin(0.5 * x) * jnp.cos(0.3 * y)\n",
        "\n",
        "  # generate range of x and y values\n",
        "  x = jnp.linspace(-10, 10, 100)\n",
        "  y = jnp.linspace(-10, 10, 100)\n",
        "\n",
        "  # gradient functions for each variable\n",
        "  # argnums = 0 → ∂T/∂x, argnums = 1 → ∂T/∂y\n",
        "  dx = jax.grad(T, argnums = 0)\n",
        "  dy = jax.grad(T, argnums = 1)\n",
        "\n",
        "  # vmap applies the gradient function elementwise across both arrays\n",
        "  # this currently pairs x[i] with y[i] → not a full 2D grid, but a 1D diagonal sampling\n",
        "  dT_dx = jax.vmap(dx, in_axes=(0,0))(x,y)\n",
        "  dT_dy = jax.vmap(dy, in_axes = (0,0))(x,y)\n",
        "\n",
        "  # returns 1D arrays of partials evaluated along matching x,y positions\n",
        "  return dT_dx, dT_dy\n",
        "\n",
        "partials_jax()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nIIFV6l83JM",
        "outputId": "710fe6d5-1867-4a66-ac0d-dba78a72ad08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([-7.0205865 , -4.543504  , -2.063769  ,  0.36547622,  2.6926434 ,\n",
              "         4.868886  ,  6.8494473 ,  8.594774  , 10.071558  , 11.253549  ,\n",
              "        12.12223   , 12.667282  , 12.886849  , 12.787532  , 12.3842325 ,\n",
              "        11.699724  , 10.76406   ,  9.613774  ,  8.290932  ,  6.8420734 ,\n",
              "         5.317027  ,  3.7677226 ,  2.2470315 ,  0.8076581 , -0.4988203 ,\n",
              "        -1.6226575 , -2.516456  , -3.1353781 , -3.437185  , -3.382194  ,\n",
              "        -2.933407  , -2.0571513 , -0.72463036,  1.08528   ,  3.3815439 ,\n",
              "         6.155123  ,  9.371793  , 12.964869  , 16.829283  , 20.818485  ,\n",
              "        24.746645  , 28.397013  , 31.537352  , 33.94153   , 35.41503   ,\n",
              "        35.820637  , 35.1       , 33.286674  , 30.507462  , 26.9707    ,\n",
              "        22.94264   , 18.715614  , 14.5729    , 10.756366  ,  7.4420366 ,\n",
              "         4.7270937 ,  2.6295786 ,  1.0994167 ,  0.03773403, -0.67991257,\n",
              "        -1.1806889 , -1.5756121 , -1.9468851 , -2.3421173 , -2.774849  ,\n",
              "        -3.229853  , -3.671257  , -4.051639  , -4.320565  , -4.431598  ,\n",
              "        -4.34734   , -4.0424547 , -3.5049772 , -2.7362537 , -1.7499774 ,\n",
              "        -0.57066405,  0.76815575,  2.2258704 ,  3.7566748 ,  5.311402  ,\n",
              "         6.839286  ,  8.289583  ,  9.613139  , 10.763768  , 11.699594  ,\n",
              "        12.384171  , 12.787509  , 12.886839  , 12.667281  , 12.122228  ,\n",
              "        11.253549  , 10.071564  ,  8.594774  ,  6.849438  ,  4.868886  ,\n",
              "         2.6926434 ,  0.36547622, -2.0637805 , -4.543504  , -7.0205865 ],      dtype=float32),\n",
              " Array([  2.029851  ,   2.9600625 ,   3.8825877 ,   4.766467  ,\n",
              "          5.581667  ,   6.299843  ,   6.8950953 ,   7.344663  ,\n",
              "          7.6295304 ,   7.734933  ,   7.650745  ,   7.3717713 ,\n",
              "          6.897875  ,   6.2340174 ,   5.39013   ,   4.3808813 ,\n",
              "          3.2253044 ,   1.9463571 ,   0.57037634,  -0.8735148 ,\n",
              "         -2.3540108 ,  -3.8381946 ,  -5.29196   ,  -6.680313  ,\n",
              "         -7.9673896 ,  -9.116088  , -10.087427  , -10.839456  ,\n",
              "        -11.32607   , -11.495844  , -11.291569  , -10.651021  ,\n",
              "         -9.5098915 ,  -7.8075686 ,  -5.496451  ,  -2.554512  ,\n",
              "          0.99943733,   5.089899  ,   9.571296  ,  14.220249  ,\n",
              "         18.73807   ,  22.765648  ,  25.912418  ,  27.797611  ,\n",
              "         28.099426  ,  26.60465   ,  23.25028   ,  18.14811   ,\n",
              "         11.586311  ,   4.005139  ,  -4.0509806 , -11.997381  ,\n",
              "        -19.279444  , -25.43699   , -30.152546  , -33.27645   ,\n",
              "        -34.82629   , -34.963455  , -33.952915  , -32.11505   ,\n",
              "        -29.7781    , -27.238491  , -24.73362   , -22.428383  ,\n",
              "        -20.41446   , -18.719248  , -17.320635  , -16.163918  ,\n",
              "        -15.177849  , -14.287952  , -13.426134  , -12.536609  ,\n",
              "        -11.578653  , -10.527018  ,  -9.370725  ,  -8.111077  ,\n",
              "         -6.7593164 ,  -5.334282  ,  -3.8602908 ,  -2.3652575 ,\n",
              "         -0.8790908 ,   0.5676808 ,   1.9450868 ,   3.2247179 ,\n",
              "          4.3806167 ,   5.390014  ,   6.233966  ,   6.8978543 ,\n",
              "          7.3717604 ,   7.650742  ,   7.734932  ,   7.6295304 ,\n",
              "          7.344663  ,   6.8950925 ,   6.299843  ,   5.581667  ,\n",
              "          4.766467  ,   3.8825843 ,   2.9600625 ,   2.029851  ],      dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solving  $4\\cdot\\sin(3x)cos(2t)$ as a further example."
      ],
      "metadata": {
        "id": "UGg1k0L5boTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partials_torch():\n",
        "  Y = lambda x,t: 4 * torch.sin(3*x) * torch.cos(2*t)\n",
        "\n",
        "  x = torch.arange(1,10,1,requires_grad = True,dtype = torch.float64)\n",
        "  t = torch.arange(1,10,1,requires_grad = True, dtype = torch.float64)\n",
        "\n",
        "  Z = Y(x,t)\n",
        "\n",
        "  Z.backward(torch.ones_like(Z))\n",
        "  return x.grad,t.grad\n",
        "\n",
        "partials_torch()"
      ],
      "metadata": {
        "id": "H3nRy0ZNHDUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821e7049-4e3f-40d9-c156-ff5fbd4278d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  4.9438,  -7.5313, -10.4981,  -1.4734,   7.6492,   6.6865,  -0.8987,\n",
              "          -4.8746,  -2.3148], dtype=torch.float64),\n",
              " tensor([-1.0266, -1.6917,  0.9212,  4.2469,  2.8302, -3.2237, -6.6304, -2.0858,\n",
              "          5.7458], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partials_jax_question2():\n",
        "\n",
        "  Y = lambda x,t: 4 * jnp.sin(3*x) * jnp.cos(2*t)\n",
        "  x = jnp.arange(1,10,1,dtype = jnp.float32)\n",
        "  t = jnp.arange(1,10,1, dtype = jnp.float32)\n",
        "  inputs = jnp.stack([x,t],axis = 1)\n",
        "\n",
        "  dx = jax.grad(Y, argnums = 0)\n",
        "  dt = jax.grad(Y, argnums = 1)\n",
        "  dY_dx = jax.vmap(dx, in_axes=(0,0))(x,t)\n",
        "  dY_dt = jax.vmap(dt, in_axes = (0,0))(x,t)\n",
        "  return dY_dx,dY_dt\n",
        "\n",
        "partials_jax_question2()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKkH4HqjDog0",
        "outputId": "e71470c0-cb04-4b17-9e13-1d82d4260f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([  4.943787 ,  -7.5313096, -10.498082 ,  -1.4733694,   7.6491895,\n",
              "          6.68653  ,  -0.8987397,  -4.874629 ,  -2.3148499], dtype=float32),\n",
              " Array([-1.0265604 , -1.6916987 ,  0.92121834,  4.246903  ,  2.8301628 ,\n",
              "        -3.2236755 , -6.630378  , -2.085752  ,  5.745809  ], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n",
        "\n",
        "## Real-World Problem: Terrain Navigation\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "An autonomous vehicle navigates terrain `H(x, y) = 10 * exp(-0.05 * x^2 - 0.1 * y^2) + 5 * cos(0.2 * x + 0.3 * y)`, where H is height (m). Needs:\n",
        "\n",
        "1. Steepest path at $(x, y) = (2, 2)$.\n",
        "2. Rate of change in 45° direction.\n",
        "3. Optimize path to target elevation."
      ],
      "metadata": {
        "id": "jxlBM-EU17fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_vector_pytorch():\n",
        "\n",
        "  # Define the scalar field (objective function)\n",
        "  # Has both exponential decay and cosine oscillations\n",
        "  H = lambda x, y: 10 * torch.exp(-0.05 * x**2 - 0.1 * y**2) + 5 * torch.cos(0.2 * x + 0.3 * y)\n",
        "\n",
        "  # Define input variables and tell PyTorch to track their gradients\n",
        "  x = torch.tensor(2.0, requires_grad=True)\n",
        "  y = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "  # Evaluate the scalar field\n",
        "  F = H(x, y)\n",
        "\n",
        "  # Compute partial derivatives ∂H/∂x and ∂H/∂y using autograd\n",
        "  F.backward()\n",
        "\n",
        "  # Store the gradients in a tensor for easier vector operations\n",
        "  grads = torch.tensor([x.grad, y.grad])\n",
        "\n",
        "  # Define a unit vector u = (√2/2, √2/2)\n",
        "  # This represents the direction in which we’ll measure the rate of change\n",
        "  unit_vector = torch.tensor([(2**0.5)/2, (2**0.5)/2])\n",
        "\n",
        "  # Directional derivative = ∇H · u\n",
        "  # Measures how fast H changes in the direction of u\n",
        "  directional_derivative = torch.dot(grads, unit_vector)\n",
        "\n",
        "  # ------------------------------\n",
        "  # Gradient Descent Demonstration\n",
        "  # ------------------------------\n",
        "\n",
        "  # Create parameters to be optimized (start values)\n",
        "  x_opt = torch.tensor(2.0, requires_grad=True)\n",
        "  y_opt = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "  # Choose optimizer — SGD will iteratively update x_opt and y_opt to minimize H\n",
        "  optimizer = torch.optim.SGD([x_opt, y_opt], lr=0.1)\n",
        "\n",
        "  # Optimization loop\n",
        "  for i in range(1000):\n",
        "    # Reset gradients to prevent accumulation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Recompute function value for current parameters\n",
        "    loss = H(x_opt, y_opt)\n",
        "\n",
        "    # Backpropagate to compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters (move opposite to gradient direction)\n",
        "    optimizer.step()\n",
        "\n",
        "  # Return results:\n",
        "  # gradients of the field, directional derivative, and optimized parameter values\n",
        "  return (\n",
        "      grads.detach().numpy(),\n",
        "      directional_derivative.detach().numpy(),\n",
        "      x_opt.detach().numpy(),\n",
        "      y_opt.detach().numpy()\n",
        "  )\n",
        "\n",
        "gradient_vector_pytorch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shyyR_2pLfHK",
        "outputId": "6aea42b5-afe0-449e-e50c-1405e9c6fe6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.9390941, -3.4574528], dtype=float32),\n",
              " array(-3.8159347, dtype=float32),\n",
              " array(4.5022163, dtype=float32),\n",
              " array(7.506556, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_vector_jax():\n",
        "  # Define the scalar field (objective function)\n",
        "  # Combines exponential decay and cosine oscillation\n",
        "  H = lambda x, y: 10 * jnp.exp(-0.05 * x**2 - 0.1 * y**2) + 5 * jnp.cos(0.2 * x + 0.3 * y)\n",
        "\n",
        "  # Define scalar inputs (like parameters)\n",
        "  x = jnp.array(2, dtype=jnp.float32)\n",
        "  y = jnp.array(2, dtype=jnp.float32)\n",
        "\n",
        "  # Compute partial derivatives ∂H/∂x and ∂H/∂y at (x, y)\n",
        "  # jax.grad returns a callable — we evaluate it immediately at (x, y)\n",
        "  dx = jax.grad(H, argnums=0)(x, y)\n",
        "  dy = jax.grad(H, argnums=1)(x, y)\n",
        "\n",
        "  # Combine partials into gradient vector\n",
        "  grads = jnp.array([dx, dy])\n",
        "\n",
        "  # Define the direction vector (unit vector)\n",
        "  u = jnp.array([(2**0.5)/2, (2**0.5)/2], dtype=jnp.float32)\n",
        "\n",
        "  # Directional derivative = ∇H · u\n",
        "  directional_derivative = jnp.dot(grads, u)\n",
        "\n",
        "  # -------------------------------\n",
        "  # Simple Gradient Descent Routine\n",
        "  # -------------------------------\n",
        "\n",
        "  # Initialize parameter vector and learning rate\n",
        "  params = jnp.array([x, y])\n",
        "  lr = 0.01\n",
        "\n",
        "  # Iteratively update parameters using gradient descent\n",
        "  for i in range(1000):\n",
        "    # Compute current gradients\n",
        "    dx = jax.grad(H, argnums=0)(params[0], params[1])\n",
        "    dy = jax.grad(H, argnums=1)(params[0], params[1])\n",
        "    grads = jnp.array([dx, dy])\n",
        "\n",
        "    # Update rule: w = w - lr * ∇H\n",
        "    params = params - lr * grads\n",
        "\n",
        "  # Return final gradient, directional derivative, and optimized parameters\n",
        "  return grads, directional_derivative, params[0], params[1]\n",
        "\n",
        "gradient_vector_jax()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt7Hveh06yGE",
        "outputId": "0af1171d-bbba-4e7c-8652-f66cf8e8231b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([ 0.00316883, -0.00661377], dtype=float32),\n",
              " Array(-3.815935, dtype=float32),\n",
              " Array(4.9638987, dtype=float32),\n",
              " Array(7.2003627, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real-World Problem: Chemical Reactor\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "A reactor’s concentration $C(T, P) = 0.01 * T^2 + 0.1 * P$ depends on temperature $T(x, y, t) = 300 * e^{(-0.05 * x^2 - 0.03 * y^2 + 0.1 * t)}$ and pressure $P(x, y, t) = 50 + 10 * sin(0.2 * x + 0.3 * y + t)$. Needs:\n",
        "\n",
        "1. Rate of change $dC/dt \\ \\text{at} \\ (x, y, t) = (1, 1, 0)$.\n",
        "2. Optimize reactor conditions.\n",
        "3. Ensure stable reaction rates.\n",
        "\n",
        "**Questions**:\n",
        "\n",
        "- How fast does concentration change at $t = 0$?\n"
      ],
      "metadata": {
        "id": "R9pjBwZ5J-op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multivariate_chain_rule_pytorch():\n",
        "  # -----------------------------\n",
        "  # Define scalar functions\n",
        "  # -----------------------------\n",
        "  # C depends on T and P (like an output variable)\n",
        "  C = lambda T, P: 0.01 * T**2 + 0.1 * P\n",
        "\n",
        "  # T and P themselves depend on x, y, t\n",
        "  T = lambda x, y, t: 300 * torch.exp(-0.05 * x**2 - 0.03 * y**2 + 0.1 * t)\n",
        "  P = lambda x, y, t: 50 + 10 * torch.sin(0.2 * x + 0.3 * y + t)\n",
        "\n",
        "  # -----------------------------\n",
        "  # Define parameters\n",
        "  # -----------------------------\n",
        "  # Set requires_grad=True so PyTorch tracks computation for gradients\n",
        "  x = torch.tensor(1.0, requires_grad=True)\n",
        "  y = torch.tensor(1.0, requires_grad=True)\n",
        "  t = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "  # -----------------------------\n",
        "  # Compute function values\n",
        "  # -----------------------------\n",
        "  # First compute intermediate functions T(x,y,t) and P(x,y,t)\n",
        "  T_func = T(x, y, t)\n",
        "  P_func = P(x, y, t)\n",
        "\n",
        "  # Then compute C(T,P) using these intermediate values\n",
        "  C_func = C(T_func, P_func)\n",
        "\n",
        "  # -----------------------------\n",
        "  # Backpropagate gradients\n",
        "  # -----------------------------\n",
        "  # This computes dC/dx, dC/dy, dC/dt using the chain rule automatically\n",
        "  C_func.backward()\n",
        "\n",
        "  # -----------------------------\n",
        "  # Return the derivative w.r.t t\n",
        "  # -----------------------------\n",
        "  return t.grad.item()\n",
        "\n",
        "multivariate_chain_rule_pytorch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrslBXcBFw4C",
        "outputId": "1c9fde0d-dc1a-4aad-cf42-20a352143923"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154.2634735107422"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multivariate_chain_rule_jax():\n",
        "    # -----------------------------\n",
        "    # Define scalar functions\n",
        "    # -----------------------------\n",
        "    C = lambda T, P: 0.01 * T**2 + 0.1 * P\n",
        "    T = lambda x, y, t: 300 * jnp.exp(-0.05 * x**2 - 0.03 * y**2 + 0.1 * t)\n",
        "    P = lambda x, y, t: 50 + 10 * jnp.sin(0.2 * x + 0.3 * y + t)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Compute derivative w.r.t t\n",
        "    # -----------------------------\n",
        "    # Wrap the chain of functions into a single callable (lambda)\n",
        "    # Now jax.grad can correctly compute ∂C/∂t\n",
        "    dt = jax.grad(\n",
        "        lambda x, y, t: C(T(x, y, t), P(x, y, t)),  # function of three variables\n",
        "        argnums=2  # derivative w.r.t t\n",
        "    )(1.0, 1.0, 0.0)  # evaluate at x=1, y=1, t=0\n",
        "\n",
        "    return dt\n",
        "\n",
        "multivariate_chain_rule_jax()\n"
      ],
      "metadata": {
        "id": "ua8zMjj8TTqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6d4a25-38a1-4c54-9ac3-8ca84920531f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(154.26347, dtype=float32, weak_type=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Integrals\n",
        "### The Challenge\n",
        "\n",
        "A metamaterial slab has density `ρ(x, y) = 2 + 0.5 * sin(0.2 * x) * cos(0.3 * y)` g/cm² over $0 ≤ x ≤ 5, 0 ≤ y ≤ 4 (cm)$.\n",
        " Needs:\n",
        "\n",
        "1. Total mass.\n",
        "\n",
        "**Questions**:\n",
        "\n",
        "- What is the total mass?\n",
        "\n",
        "- worked example by hand yielded 43.58g"
      ],
      "metadata": {
        "id": "MFPImyN9-cqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import dblquad\n",
        "\n",
        "# -----------------------------\n",
        "# Define the density function\n",
        "# -----------------------------\n",
        "# rho(y,x) gives the mass density at a point (x,y) on the slab\n",
        "rho = lambda y, x: 2 + 0.5 * np.sin(0.2 * x) * np.cos(0.3 * y)\n",
        "\n",
        "# -----------------------------\n",
        "# Compute total mass via double integral\n",
        "# -----------------------------\n",
        "# dblquad integrates a function over a rectangular region:\n",
        "#   first argument: function to integrate (rho)\n",
        "#   second & third: x-limits (a, b)\n",
        "#   fourth & fifth: y-limits as functions of x (here constant 0 to 4)\n",
        "total_mass, error = dblquad(\n",
        "    rho,          # function to integrate\n",
        "    0, 5,         # x goes from 0 to 5\n",
        "    lambda x: 0,  # y lower limit\n",
        "    lambda x: 4   # y upper limit\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Print result\n",
        "# -----------------------------\n",
        "print(f\"The total mass of the slab is {total_mass:.2f} g\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv9rzcCA-suU",
        "outputId": "ebd81c50-8206-4281-fe97-906636b1d36a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total mass of the slab is 43.57 g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lagrange Multipliers\n",
        "## Real-World Problem: Antenna Design\n",
        "\n",
        "### The Challenge\n",
        "\n",
        "An antenna’s gain is $G(x, y) = 10 - 0.5 * x^2 - 0.3 * y^2 + 0.2 * x * y$, with constraint $x + y = 8 \\ \\text{cm}$\n",
        "Needs:\n",
        "\n",
        "1. Maximize gain G.\n",
        "2. Verify optimal dimensions.\n",
        "3. Ensure computational stability.\n",
        "\n",
        "**Questions**:\n",
        "\n",
        "- What dimensions maximize gain?\n",
        "- Does it satisfy x + y = 8?  \n",
        "\n",
        "Why It Matters: Constrained optimization balances properties in topology optimization research."
      ],
      "metadata": {
        "id": "NclYnQg1KMjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# --------------------------------------\n",
        "# Define the objective function\n",
        "# --------------------------------------\n",
        "# G(x, y) represents a gain function we want to maximize.\n",
        "# Since scipy.minimize() minimizes by default, we negate the function.\n",
        "G = lambda xy: -(10 - 0.5 * xy[0]**2 - 0.3 * xy[1]**2 + 0.2 * xy[0] * xy[1])\n",
        "\n",
        "# --------------------------------------\n",
        "# Define the constraint\n",
        "# --------------------------------------\n",
        "# The constraint is an equality: x + y = 8\n",
        "# 'type': 'eq' means the constraint must equal zero → xy[0] + xy[1] - 8 = 0\n",
        "constraint = {'type': 'eq', 'fun': lambda xy: xy[0] + xy[1] - 8}\n",
        "\n",
        "# --------------------------------------\n",
        "# Perform optimization\n",
        "# --------------------------------------\n",
        "# initial guess = [1,1]\n",
        "# method = 'SLSQP' (Sequential Least Squares Quadratic Programming)\n",
        "# used for problems with equality and inequality constraints\n",
        "result = minimize(G, [1, 1], constraints=constraint, method='SLSQP')\n",
        "\n",
        "# unpack optimized values\n",
        "x, y = result.x\n",
        "\n",
        "# --------------------------------------\n",
        "# Display the optimal values and result\n",
        "# --------------------------------------\n",
        "print(f\"SciPy: Optimal (x, y) = ({x:.2f}, {y:.2f}), Gain = {-result.fun:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cg8kV_P_B7P",
        "outputId": "7d0d8e74-7fd9-4571-bf70-562b193e3857"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SciPy: Optimal (x, y) = (3.20, 4.80), Gain = 1.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rriHDpQYJzEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}