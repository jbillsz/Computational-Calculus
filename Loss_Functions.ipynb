{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Functions**\n",
        "\n",
        "**Loss functions** are crucial for training neural networks and improving task accuracy. They fall into two main categories corresponding to supervised learning types:\n",
        "\n",
        "1. **Regression Losses** - MSE, MAE, RMSE\n",
        "2. **Classification Losses** - Cross Entropy(Variations: Binary, Categorical, Sparse Categorical), Huber Loss\n",
        "\n",
        "I'll demonstrate implementations across sklearn, JAX, and PyTorch, focusing on the most common loss functions in ML and deep learning. This section assumes models are already built and initialized—when you see 'model', interpret it as the neural network architecture within each framework.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "543j60H3q9_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Squared Error Loss Function\n",
        "\n",
        "$\\text{MSE} = 1/n ∑ᵢ₌₁ⁿ (yᵢ - ŷᵢ)²$\n",
        "\n",
        "Where:\n",
        "\n",
        "$\\text{n}$ = number of samples\n",
        "\n",
        "$yᵢ$ = true value for sample i\n",
        "\n",
        "$ŷᵢ$ = predicted value for sample i\n",
        "\n",
        "$∑$ = summation over all samples"
      ],
      "metadata": {
        "id": "xw4tG0-vneaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Sklearn Metrics api"
      ],
      "metadata": {
        "id": "MT0PcID8n9jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIvdbXHjmthJ",
        "outputId": "b7abe249-e994-44bb-843c-f93381653458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1744077613492566"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Generate some random data\n",
        "y_true = np.random.rand(100)\n",
        "y_pred = np.random.rand(100)\n",
        "\n",
        "# Calculate the MSE\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "mse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using jax"
      ],
      "metadata": {
        "id": "FKctxAIWoBkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "  \"\"\"Takes in arrays of y_true and y_pred. Array shapes must be the same\"\"\"\n",
        "  y_true = jnp.array(y_true)\n",
        "  y_pred = jnp.array(y_pred)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return jnp.mean(jnp.square(y_true - y_pred))\n",
        "jax.jit(mse(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba_O0ObOn5su",
        "outputId": "f4a45949-d187-45db-cd5f-5b6663e78192"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(0.17440777, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Taking it a step further for neural networks\n",
        ""
      ],
      "metadata": {
        "id": "O-JNaQ_spFRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, params, x):\n",
        "  # define the forward pass for the network\n",
        "  y_true = jnp.array(y_true)\n",
        "  y_pred = model.apply(params,x)\n",
        "  # Assess shape and then calculate loss\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return jnp.mean(jnp.square(y_true - y_pred))\n",
        ""
      ],
      "metadata": {
        "id": "P7Jv5AmFomkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pytorch"
      ],
      "metadata": {
        "id": "w1qybCJWp1OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "  # change numpy arrays into torch tensors\n",
        "  y_true = torch.tensor(y_true)\n",
        "  y_pred = torch.tensor(y_pred)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    # make predictions\n",
        "    return torch.mean(torch.square(y_true - y_pred))\n",
        "  return None\n",
        "\n",
        "mse(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx4HKYoCpxZC",
        "outputId": "9f31384e-74fc-4fc5-e6bd-f15c84d3109b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1744, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking it a step further for Neural networks"
      ],
      "metadata": {
        "id": "EDeF6S6-qMjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, x):\n",
        "  # define the forward pass for the network\n",
        "  y_pred = model.forward(x)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return torch.mean(torch.square(y_true - y_pred))\n",
        "\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "8OxoBGtAp9-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary CrossEntropy\n",
        "$\\text{BCE} = -[y_{true} * log(y_{pred}) + (1 - y_{true}) * log(1 - y_{pred})]$\n",
        "\n",
        "y_true = one-hot encoded true labels\n",
        "\n",
        "y_pred = predicted probabilities (after sigmoid/softmax)"
      ],
      "metadata": {
        "id": "OTMfrq5pxaFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sklearn."
      ],
      "metadata": {
        "id": "0o_ysggs2ujF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.random.randint(low=0, high=2, size = (1,4))\n",
        "y_true\n",
        "\n",
        "# y_pred is a probability of what y_true at it's index is.\n",
        "y_pred = np.random.rand(1,4)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwEUYq__xris",
        "outputId": "2b50a93c-46c4-4521-fef8-4efaa777c042"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36016328, 0.42604236, 0.2383781 , 0.09121179]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "log_loss(y_true, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoDalira2ymJ",
        "outputId": "ff73946f-27d6-4235-e753-cc7f654bd214"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.268985431428761"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Jax"
      ],
      "metadata": {
        "id": "u96Lp43F1pkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossEntropy(y_true, y_pred):\n",
        "  y_true = jnp.asarray(y_true)\n",
        "  y_pred = jnp.asarray(y_pred)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return -jnp.sum(y_true * jnp.log(y_pred) + (1 - y_true) * jnp.log(1 - y_pred))\n",
        "jax.jit(CrossEntropy(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivfHrKKFyAwI",
        "outputId": "1ac86feb-a73d-4fda-d752-0c09121de8ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(4.5412903, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a step for neural networks"
      ],
      "metadata": {
        "id": "TLN7s9Ou1rbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossEntropy(y_true, params, x):\n",
        "  y_true = jnp.asarray(y_true)\n",
        "  #forward pass to predict y\n",
        "  y_pred = model.apply(params, x)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return -jnp.sum(y_true * jnp.log(y_pred) + (1 - y_true) * jnp.log(1 - y_pred))\n",
        "jax.jit(CrossEntropy(y_true, y_pred)) # jit wrapper for faster just in time compilations"
      ],
      "metadata": {
        "id": "30Q5rFfGyeQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pytorch"
      ],
      "metadata": {
        "id": "m4a4lgWl1654"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossEntropy(y_true, y_pred):\n",
        "  y_true = torch.tensor(y_true)\n",
        "  y_pred = torch.tensor(y_pred)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return -torch.sum((y_true * torch.log(y_pred)) + (1 - y_true) * torch.log(1 - y_pred))\n",
        "CrossEntropy(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXnLzmgk1_Lv",
        "outputId": "805779f0-e92f-4270-f390-b8764996dc6f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5413, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taking it a step Further for Neural networks"
      ],
      "metadata": {
        "id": "NqpkQiiV2Tyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossEntropy(y_true, x):\n",
        "  y_true = torch.tensor(y_true)\n",
        "  y_pred = model.forwar(x)\n",
        "  if y_true.shape != y_pred.shape:\n",
        "    raise ValueError(f\"Shape mismatch: y_true {y_true.shape} vs y_pred {y_pred.shape}\")\n",
        "  else:\n",
        "    return -torch.sum(y_true * torch.log(y_pred) - (1 - y_true) * torch.log(1 - y_pred))"
      ],
      "metadata": {
        "id": "GkpUl-Gz2K7r"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary:\n",
        "I implemented MSE and BCE manually in both PyTorch and JAX/Flax to show how loss functions work at the mathematical and functional-programming level. These two losses are the simplest representatives of regression and binary classification, so implementing them proves the core structure of how predictions, targets, and gradients interact.\n",
        "\n",
        "However, for real training it is safer and more efficient to use the built-in loss functions. Framework implementations handle critical issues like numerical stability (clamping, safe logs, overflow protection), memory efficiency (fused ops, optimized kernels), and dtype/device correctness. They also avoid silent bugs that arise in custom code during large-scale training.\n",
        "\n",
        "So the point of manual losses was to demonstrate understanding—while the actual training relies on the optimized, stable, framework-provided versions."
      ],
      "metadata": {
        "id": "4neAjHi55JRS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vv08OfzL2hg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}