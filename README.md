ğŸ§® Computational Calculus

This project explores calculus through computation, bridging mathematical theory with modern automatic differentiation frameworks: PyTorch and JAX.
It provides hands-on implementations for learners, researchers, and engineers, making derivatives, parametric analysis, and implicit differentiation interactive and reproducible.

âš¡ Features

Basic Differentiation: Single-variable derivatives using autograd.

Vectorized Derivatives: Efficient computation for multiple points using torch.autograd.grad and jax.vmap.

Parametric Equations: Compute derivatives of functions w.r.t time (dy/dx for x(t) and y(t)).

Implicit Differentiation: Solve F(x, y) = 0 numerically and compute dy/dx automatically.

Integration-Ready Workflow: Structured QA-style checklists for gradient computation, ensuring clarity and reproducibility.

ğŸ“š Calculus Concepts Covered

âš¡ Power Rule: Derivatives of the form 

ğŸ”— Chain Rule: Handling nested functions and compositions

âœ–ï¸ Product & Quotient Rules: Derivatives of products and ratios of functions

ğŸ“ Turning Points / Extrema: Finding maxima, minima, and critical points

ğŸŒ€ Parametric Differentiation: Compute dy/dx when x(t) and y(t) are functions of time

#ğŸ§© Implicit Differentiation: Solve F(x,y)=0 and compute dy/dx automatically

# ğŸ› ï¸ Technical Skills

PyTorch: autograd, vectorized gradients

JAX: grad, vmap, vectorized differentiation

Numerical Methods: Root-finding using scipy.optimize.fsolve

Differentiation Techniques: Parametric and implicit differentiation

Workflow: Systematic QA-driven computational process

# ğŸš€ Applications

Physics, engineering, and AI simulations requiring derivatives

Parametric motion analysis (e.g., drones, projectiles)

Computational modeling of physical systems with constraints

Educational resource for programmatically learning calculus

# ğŸ’¡ Why This Project?

This repository turns theory into computation:

Learn calculus concepts interactively.

Apply automatic differentiation for practical problems.

Follow QA checklists to avoid common pitfalls in gradient computation.

# ğŸ”® Future Extensions

âˆ« Integration: Numerical and symbolic methods

ğŸŒ Multivariable Calculus: Partial derivatives, gradients, and Jacobians

ğŸ“ˆ Differential Equations: ODEs with numerical solvers and autograd
